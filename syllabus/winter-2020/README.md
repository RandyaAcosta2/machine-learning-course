
### [Session 1, January 7, 2020: Introduction to Machine Learning](./../../docs/introduction/README.md)

-----------

### [Session 2, January 9, 2020: Linear Regression](./../../docs/linear_regression/README.md)

----------

### [Session 3, January 14, 2020: Logistic Regression -- scikit](./../../docs/logistic_regression/README.md)
<!--
spam/nospam: 
https://medium.com/@julsimon/building-a-spam-classifier-pyspark-mllib-vs-sagemaker-xgboost-1980158a900f
https://towardsdatascience.com/spam-detection-with-logistic-regression-23e3709e522
https://www.kaggle.com/abhikaggle8/pima-diabetes-classification/data
-->

--------

### [Session 4, January 16, 2020: Logistic Regression -- Spark ML](./../../docs/logistic_regression/README.md)

-----------

### [Session 5, January 21, 2020: TF-IDF -- Spark ML](./../../docs/TF-IDF/README.md)
* Students Project Presentation (LDA)

-----------

### Session 6, January 23, 2020: Student Project Presentations

--------

### [Session 7, January 28, 2020: K-means](./../../docs/kmeans/README.md)


--------

### Session 8, PCA

--------

### Session 9, LDA

-------

### Session 10: SVM

-------

### Session 11: Frequent Pattern Mining

-------

### Handling Non-Numeric Data:

* [Handling Categorical Data in Python](ttps://www.datacamp.com/community/tutorials/categorical-data)

* [Handling Non-Numeric Data (16 minutes video)](https://www.youtube.com/watch?v=8p6XaQSIFpY&feature=youtu.be)


### Underfitting and Overfitting

* A model that generalizes well is a model 
  that is neither underfit nor overfit.

* Underfitting

````
    Underfitting occurs when a model can‚Äôt 
    accurately capture the dependencies among 
    data, usually as a consequence of its own 
    simplicity. It often yields a low ùëÖ¬≤ with 
    known data and bad generalization capabilities 
    when applied with new data.
````

* Overfitting

````
    Overfitting  happens  when a  model learns  
    both dependencies  among  data  and random 
    fluctuations. In other words, a model learns 
    the existing data too well. Complex models, 
    which have many features or terms, are often 
    prone to overfitting.    When applied to known 
    data, such models usually yield high ùëÖ¬≤. However, 
    they  often  don‚Äôt  generalize  well  and  have 
    significantly lower ùëÖ¬≤ when used with new data.
````

* [What Are Overfitting and Underfitting in Machine Learning?](https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690)

* [Overfitting and Underfitting in Machine Learning - video 17 minutes](https://www.youtube.com/watch?v=j9_yzC-x-js)
